{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A3C_disc_max_dist.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wQso0DMQvaZa","colab_type":"code","colab":{}},"source":["from multiprocessing import Process\n","#from time import sleep\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import gym\n","import tensorflow as tf\n","\n","# tf Graph, ops\n","class ACNet(object):\n","    def __init__(self, scope, sess, globalAC=None):\n","        self.sess = sess\n","        OPT_A = tf.train.AdamOptimizer(actor_alpha, beta1=0.99, beta2=0.999, name='OPT_A')\n","        OPT_C = tf.train.AdamOptimizer(critic_alpha, beta1=0.99, beta2=0.999, name='OPT_C')          \n","        \n","        if scope == net_scope: # global\n","            with tf.variable_scope(scope):\n","                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n","                # create global net\n","                self.actor_params, self.critic_params = self._create_net(scope)[-2:] # only require params\n","                \n","        else: # local\n","            with tf.variable_scope(scope):\n","                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n","                self.a = tf.placeholder(tf.int32, [None, ], 'A')\n","                self.critic_target = tf.placeholder(tf.float32, [None, 1], 'critic_target')\n","                self.baselined_returns = tf.placeholder(tf.float32, [None, 1], 'baselined_returns') # for calculating advantage \n","                # create local net\n","                self.action_prob, self.V, self.actor_params, self.critic_params = self._create_net(scope)\n","                    \n","                TD_err = tf.subtract(self.critic_target, self.V, name='TD_err')\n","                with tf.name_scope('actor_loss'):\n","                    log_prob = tf.reduce_sum(tf.log(self.action_prob + 1e-5) * tf.one_hot(self.a, num_actions, dtype=tf.float32), axis=1, keep_dims=True)\n","                    actor_component = log_prob * tf.stop_gradient(self.baselined_returns)\n","                    # entropy for exploration\n","                    entropy = -tf.reduce_sum(self.action_prob * tf.log(self.action_prob + 1e-5), axis=1, keep_dims=True)  # encourage exploration\n","                    self.actor_loss = tf.reduce_mean( -(ENTROPY_BETA * entropy + actor_component) )                                        \n","                with tf.name_scope('critic_loss'):\n","                    self.critic_loss = tf.reduce_mean(tf.square(TD_err))                      \n","                # accumulated gradients for local actor    \n","                with tf.name_scope('local_actor_grad'):                   \n","                    self.actor_zero_op, self.actor_accumu_op, self.actor_apply_op, actor_accum = self.accumu_grad(OPT_A, self.actor_loss, scope=scope + '/actor')\n","                # ********** accumulated gradients for local critic **********\n","                with tf.name_scope('local_critic_grad'):\n","                    self.critic_zero_op, self.critic_accumu_op, self.critic_apply_op, critic_accum = self.accumu_grad(OPT_C, self.critic_loss, scope=scope + '/critic')\n","                    \n","            with tf.name_scope('params'): # push/pull from local/worker perspective\n","                with tf.name_scope('push_to_global'):\n","                    self.push_actor_params = OPT_A.apply_gradients(zip(actor_accum, globalAC.actor_params))\n","                    self.push_critic_params = OPT_C.apply_gradients(zip(critic_accum, globalAC.critic_params))\n","                with tf.name_scope('pull_fr_global'):\n","                    self.pull_actor_params = [local_params.assign(global_params) for local_params, global_params in zip(self.actor_params, globalAC.actor_params)]\n","                    self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, globalAC.critic_params)]                    \n","                    \n","    def _create_net(self, scope):\n","        w_init = tf.glorot_uniform_initializer()\n","        with tf.variable_scope('actor'):\n","            hidden = tf.layers.dense(self.s, actor_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n","            action_prob = tf.layers.dense(hidden, num_actions, tf.nn.softmax, kernel_initializer=w_init, name='action_prob')        \n","        with tf.variable_scope('critic'):\n","            hidden = tf.layers.dense(self.s, critic_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n","            V = tf.layers.dense(hidden, 1, kernel_initializer=w_init, name='V')         \n","        actor_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n","        critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')       \n","        return action_prob, V, actor_params, critic_params\n","\n","    def accumu_grad(self, OPT, loss, scope):\n","        # retrieve trainable variables in scope of graph\n","        #tvs = tf.trainable_variables(scope=scope + '/actor')\n","        tvs = tf.trainable_variables(scope=scope)\n","        # ceate a list of variables with the same shape as the trainable\n","        accumu = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n","        zero_op = [tv.assign(tf.zeros_like(tv)) for tv in accumu] # initialized with 0s\n","        gvs = OPT.compute_gradients(loss, tvs) # obtain list of gradients & variables\n","        #gvs = [(tf.where( tf.is_nan(grad), tf.zeros_like(grad), grad ), var) for grad, var in gvs]\n","        # adds to each element from the list you initialized earlier with zeros its gradient \n","        # accumu and gvs are in same shape, index 0 is grads, index 1 is vars\n","        accumu_op = [accumu[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n","        apply_op = OPT.apply_gradients([(accumu[i], gv[1]) for i, gv in enumerate(gvs)]) # apply grads\n","        return zero_op, accumu_op, apply_op, accumu      \n","      \n","    def push_global_actor(self, feed_dict): \n","        SESS = self.sess\n","        SESS.run([self.push_actor_params], feed_dict)  \n","\n","    def push_global_critic(self, feed_dict):  \n","        SESS = self.sess\n","        SESS.run([self.push_critic_params], feed_dict)         \n","        \n","    def pull_global(self):  \n","        SESS = self.sess\n","        SESS.run([self.pull_actor_params, self.pull_critic_params])\n","\n","    def choose_action(self, s):  \n","        SESS = self.sess\n","        prob_weights = SESS.run(self.action_prob, feed_dict={self.s: s[None, :]})\n","        action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) \n","        return action             \n","        \n","    def init_grad_storage_actor(self):\n","        SESS = self.sess\n","        SESS.run(self.actor_zero_op)\n","        \n","    def accumu_grad_actor(self, feed_dict):\n","        SESS = self.sess\n","        SESS.run([self.actor_accumu_op], feed_dict)          \n","    \n","    def apply_accumu_grad_actor(self, feed_dict):\n","        SESS = self.sess\n","        SESS.run([self.actor_apply_op], feed_dict)   \n","        \n","    def init_grad_storage_critic(self):\n","        SESS = self.sess\n","        SESS.run(self.critic_zero_op)\n","        \n","    def accumu_grad_critic(self, feed_dict):\n","        SESS = self.sess\n","        SESS.run([self.critic_accumu_op], feed_dict)          \n","    \n","    def apply_accumu_grad_critic(self, feed_dict):\n","        SESS = self.sess\n","        SESS.run([self.critic_apply_op], feed_dict)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8n6s3a5qIvP","colab_type":"code","colab":{}},"source":["class Worker(object): # local only\n","    def __init__(self, name, globalAC, GLOBAL_EP, GLOBAL_RUNNING_R, sess):\n","        self.env = gym.make(game)\n","        self.name = name\n","        self.AC = ACNet(name, sess, globalAC)\n","        self.sess = sess\n","        self.GLOBAL_EP = GLOBAL_EP\n","        self.GLOBAL_RUNNING_R = GLOBAL_RUNNING_R\n","        \n","    def work(self):\n","        #global GLOBAL_EP, GLOBAL_RUNNING_R\n","        T = 0\n","        t = 0\n","        SESS = self.sess\n","        GLOBAL_EP = self.GLOBAL_EP\n","        GLOBAL_RUNNING_R = self.GLOBAL_RUNNING_R\n","        \n","        #while not COORD.should_stop() and GLOBAL_EP < max_global_episodes:\n","        while SESS.run(GLOBAL_EP) < max_global_episodes:\n","            s = self.env.reset()\n","            ep_r = 0 # reward per episode\n","            done = False\n","            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n","            self.AC.pull_global()\n","            while not done:\n","                a = self.AC.choose_action(s)\n","                s_, r, done, info = self.env.step(a)\n","                ep_r += r\n","                buffer_s.append(s)\n","                buffer_a.append(a)\n","                buffer_r.append(r)\n","                buffer_done.append(done)                \n","                s = s_\n","                t += 1\n","            \n","            # if statement will always be done in this case... \n","            # possible future modification\n","            if done:\n","                V_s = 0   \n","            else:\n","                V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n","            \n","            # critic related\n","            critic_target = self.discount_rewards(buffer_r, GAMMA, V_s)\n","            \n","            buffer_s, buffer_a, critic_target = np.vstack(buffer_s), np.array(buffer_a), np.vstack(critic_target)\n","            feed_dict = {self.AC.s: buffer_s, self.AC.critic_target: critic_target}                         \n","            self.AC.accumu_grad_critic(feed_dict) # accumulating gradients for local critic  \n","            self.AC.apply_accumu_grad_critic(feed_dict) \n","            \n","            baseline = SESS.run(self.AC.V, {self.AC.s: buffer_s}) # Value function\n","            epr = np.vstack(buffer_r).astype(np.float32)\n","            #V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n","            #n_step_targets = self.n_step_targets_missing(epr, baseline, GAMMA, N_step) # Q values\n","            n_step_targets = self.n_step_targets_max(epr, baseline, V_s, GAMMA, N_step) # Q values\n","            # Advantage function\n","            baselined_returns = n_step_targets - baseline\n","\n","            feed_dict = {self.AC.s: buffer_s, self.AC.a: buffer_a, self.AC.critic_target: critic_target, self.AC.baselined_returns: baselined_returns}            \n","            self.AC.accumu_grad_actor(feed_dict) # accumulating gradients for local actor  \n","            \n","            # update\n","            self.AC.push_global_actor(feed_dict)                \n","            self.AC.push_global_critic(feed_dict)\n","            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n","            self.AC.pull_global()\n","              \n","            if T % delay_rate == 0: # delay clearing of local gradients storage to reduce noise\n","                # apply to local\n","                self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n","                self.AC.init_grad_storage_critic() \n","                \n","            #GLOBAL_EP += 1                   \n","            SESS.run(GLOBAL_EP.assign_add(1.0))\n","            #GLOBAL_RUNNING_R.append(ep_r) # for display\n","            qe = GLOBAL_RUNNING_R.enqueue(ep_r)\n","            SESS.run(qe)            \n","            \n","    def discount_rewards(self, r, gamma, running_add):\n","      \"\"\"Take 1D float array of rewards and compute discounted reward \"\"\"\n","      discounted_r = np.zeros_like(r)\n","      #running_add = 0\n","      for t in reversed(range(len(r))):\n","          running_add = running_add * gamma + r[t]\n","          discounted_r[t] = running_add\n","      return discounted_r \n","  \n","    # As n increase, variance increase.\n","    # Create a function that returns an array of n-step targets, one for each timestep:\n","    # target[t] = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^n V(s_{t+n})\n","    # Where r_t is given by episode reward (epr) and V(s_n) is given by the baselines.\n","    \n","    def n_step_targets_missing(self, epr, baselines, gamma, N):\n","      targets = np.zeros_like(epr)    \n","      if N > epr.size:\n","        N = epr.size\n","      for t in range(epr.size):    \n","        for n in range(N):\n","          if t+n == epr.size:            \n","            break # missing terms treated as 0\n","          if n == N-1: # last term\n","            targets[t] += (gamma**n) * baselines[t+n]\n","          else:\n","            targets[t] += (gamma**n) * epr[t+n] \n","      return targets  \n","    \n","    def n_step_targets_max(self, epr, baselines, v_s_, gamma, N):\n","      targets = np.zeros_like(epr)    \n","      if N > epr.size:\n","        N = epr.size\n","      for t in range(epr.size):  \n","        #print(\"t=\", t)\n","        for n in range(N):\n","          #print(\"n=\", n)\n","          if t+n == epr.size:            \n","            targets[t] += (gamma**n) * v_s_ # use max steps available\n","            break \n","          if n == N-1: # last term\n","            targets[t] += (gamma**n) * baselines[t+n]\n","          else:\n","            targets[t] += (gamma**n) * epr[t+n] \n","      return targets \n","    \"\"\"\n","    def n_step_targets_3(self, r, B, g, N):\n","      if N >= len(r):\n","        N = len(r)-1\n","      \n","      T = np.zeros_like(r)             \n","    \n","      # Non n-steps ops without baseline terms\n","      t = r.size-1\n","      T[t] = r[t] # last entry, do 0 step\n","      for n in range(1,N): # n = 1..N-1, do 1 step to N-1 step\n","        t = t-1\n","        for i in range(n): # get 0..n-1 gamma raised r terms\n","          T[t] += g**i * r[t+i] \n","    \n","      # Non n-steps ops with baseline terms\n","      t = r.size-1\n","      for j in range(1,N): # 1..N-1\n","        t = t-1\n","        T[t] += g**j * B[N]\n","    \n","      # n-steps ops without baseline\n","      for t in range(r.size-N): # 0..r.size-N-1\n","        for k in range(N):\n","          T[t] += g**k * r[t+k] \n","    \n","      # n-steps ops with baseline\n","      for t in range(r.size-N): # 0..r.size-N-1\n","        T[t] += g**N * B[t+N]\n","    \n","      return T \n","    \"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0nYHeKBL-D1","colab_type":"code","colab":{}},"source":["game = 'CartPole-v0'\n","#env = gym.make(game).unwrapped\n","env = gym.make(game)\n","\n","num_obvs = env.observation_space.shape[0]\n","num_actions = env.action_space.n\n","\n","net_scope = 'global'\n","max_global_episodes = 500#5 #500\n","delay_rate = 4000 # T steps\n","\n","GAMMA = 0.999 #0.99\n","ENTROPY_BETA = 0.1 #0.01\n","actor_alpha = 0.01   \n","critic_alpha = 0.01   \n","actor_hidden = 64#4 #128 #200\n","critic_hidden = 64#4 #128 #200\n","N_step = 15"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bhd82T1eiWam","outputId":"b3333e3c-bcae-46b4-a818-39e8aa6bb2c2","executionInfo":{"status":"ok","timestamp":1560786105639,"user_tz":-480,"elapsed":183914,"user":{"displayName":"H C","photoUrl":"https://lh5.googleusercontent.com/-CRr1M6G7Q8s/AAAAAAAAAAI/AAAAAAAAABo/s1oBNc9JuHw/s64/photo.jpg","userId":"02161151882970450665"}},"colab":{"base_uri":"https://localhost:8080/","height":1323}},"source":["cluster = tf.train.ClusterSpec({\n","    \"worker\": [\"localhost:2223\",\n","               \"localhost:2224\"\n","              ],\n","    \"ps\": [\"localhost:2225\"]\n","})\n","\n","def parameter_server():\n","    #tf.reset_default_graph()\n","    \n","    server = tf.train.Server(cluster,\n","                             job_name=\"ps\",\n","                             task_index=0)\n","    sess = tf.Session(target=server.target)        \n","    \n","    with tf.device(\"/job:ps/task:0\"):\n","        GLOBAL_AC = ACNet(net_scope, sess, globalAC=None) # only need its params\n","        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes   \n","        # a queue of ep_r\n","        GLOBAL_RUNNING_R = tf.FIFOQueue(max_global_episodes, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")        \n","    \n","    print(\"Parameter server: waiting for cluster connection...\")\n","    sess.run(tf.report_uninitialized_variables())\n","    print(\"Parameter server: cluster ready!\")\n","    \n","    print(\"Parameter server: initializing variables...\")\n","    sess.run(tf.global_variables_initializer())\n","    print(\"Parameter server: variables initialized\")\n","    \n","    while True:\n","        time.sleep(1.0)\n","        #print(\"ps 1 GLOBAL_EP: \", sess.run(GLOBAL_EP))\n","        #print(\"ps 1 GLOBAL_RUNNING_R.size(): \", sess.run(GLOBAL_RUNNING_R.size()))  \n","        if sess.run(GLOBAL_RUNNING_R.size()) >= max_global_episodes: # GLOBAL_EP starts from 0, hence +1 to max_global_episodes          \n","            time.sleep(5.0)\n","            #print(\"ps 2 GLOBAL_RUNNING_R.size(): \", sess.run(GLOBAL_RUNNING_R.size()))  \n","            GLOBAL_RUNNING_R_list = []\n","            for j in range(sess.run(GLOBAL_RUNNING_R.size())):\n","                ep_r = sess.run(GLOBAL_RUNNING_R.dequeue())\n","                GLOBAL_RUNNING_R_list.append(ep_r) # for display\n","            break\n","              \n","    # display\n","    plt.plot(np.arange(len(GLOBAL_RUNNING_R_list)), GLOBAL_RUNNING_R_list)\n","    plt.xlabel('episode')\n","    plt.ylabel('reward')\n","    plt.show()  \n","\n","    #print(\"Parameter server: blocking...\")\n","    #server.join() # currently blocks forever    \n","    print(\"Parameter server: ended...\")\n","\n","def worker(worker_n): \n","    #tf.reset_default_graph()\n","    \n","    server = tf.train.Server(cluster,\n","                             job_name=\"worker\",\n","                             task_index=worker_n)\n","    sess = tf.Session(target=server.target)  \n","  \n","    with tf.device(\"/job:ps/task:0\"):\n","        GLOBAL_AC = ACNet(net_scope, sess, globalAC=None) # only need its params\n","        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes\n","        # a queue of ep_r\n","        GLOBAL_RUNNING_R = tf.FIFOQueue(max_global_episodes, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")   \n","    \"\"\"\n","    with tf.device(tf.train.replica_device_setter(\n","                        worker_device='/job:worker/task:' + str(worker_n),\n","                        cluster=cluster)):\n","    \"\"\"                        \n","    print(\"Worker %d: waiting for cluster connection...\" % worker_n)\n","    sess.run(tf.report_uninitialized_variables())\n","    print(\"Worker %d: cluster ready!\" % worker_n)\n","    \n","    #while sess.run(tf.report_uninitialized_variables()):\n","    while (sess.run(tf.report_uninitialized_variables())).any(): # ********** .any() .all() **********\n","        print(\"Worker %d: waiting for variable initialization...\" % worker_n)\n","        time.sleep(1.0)\n","    print(\"Worker %d: variables initialized\" % worker_n)\n","    \n","    w = Worker(str(worker_n), GLOBAL_AC, GLOBAL_EP, GLOBAL_RUNNING_R, sess) \n","    print(\"Worker %d: created\" % worker_n)\n","    \n","    sess.run(tf.global_variables_initializer()) # got to initialize after Worker creation\n","    w.work()\n","    print(\"Worker %d: w.work()\" % worker_n)\n","          \n","    #print(\"Worker %d: blocking...\" % worker_n)\n","    server.join() # currently blocks forever\n","    print(\"Worker %d: ended...\" % worker_n)\n","    \n","start_time = time.time()\n","\n","ps_proc = Process(target=parameter_server, daemon=True)\n","w1_proc = Process(target=worker, args=(0, ), daemon=True)\n","w2_proc = Process(target=worker, args=(1, ), daemon=True)\n","\n","ps_proc.start()\n","w1_proc.start()\n","w2_proc.start()\n","\n","# if not join, parent will terminate before children \n","# & children will terminate as well cuz children are daemon\n","ps_proc.join() \n","#w1_proc.join()\n","#w2_proc.join() \n","    \n","for proc in [w1_proc, w2_proc, ps_proc]:\n","    proc.terminate() # only way to kill server is to kill it's process\n","        \n","print('All done.')     \n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0617 15:38:45.080276 139768905377664 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructorWARNING: Logging before flag parsing goes to stderr.\n","\n","W0617 15:38:45.090162 139768905377664 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructorW0617 15:38:45.119013 139768905377664 deprecation.py:323] From <ipython-input-1-28278129bb5c>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","\n","W0617 15:38:45.154158 139768905377664 deprecation.py:323] From <ipython-input-1-28278129bb5c>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0617 15:38:45.183476 139768905377664 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0617 15:38:45.223509 139768905377664 deprecation.py:323] From <ipython-input-1-28278129bb5c>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 1: waiting for cluster connection...\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 15:38:45.967936 139768905377664 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 1: cluster ready!\n","Parameter server: waiting for cluster connection...\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 15:38:46.164970 139768905377664 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 1: waiting for variable initialization...\n","Worker 0: waiting for cluster connection...\n","Parameter server: cluster ready!\n","Parameter server: initializing variables...\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 15:38:46.255765 139768905377664 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 0: cluster ready!\n","Parameter server: variables initialized\n","Worker 0: variables initialized\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 15:38:46.430003 139768905377664 deprecation.py:506] From <ipython-input-1-28278129bb5c>:35: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","W0617 15:38:46.450315 139768905377664 deprecation.py:323] From <ipython-input-1-28278129bb5c>:74: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 0: created\n","Worker 1: variables initialized\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 15:38:47.394288 139768905377664 deprecation.py:506] From <ipython-input-1-28278129bb5c>:35: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","W0617 15:38:47.418755 139768905377664 deprecation.py:323] From <ipython-input-1-28278129bb5c>:74: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["Worker 1: created\n","Worker 0: w.work()\n","Worker 1: w.work()\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Parameter server: ended...\n","All done.\n","--- 179.56177830696106 seconds ---\n"],"name":"stdout"}]}]}