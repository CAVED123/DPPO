{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3C_disc_miss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmiXBukYvLDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "A3C (Asynchronous Advantage Actor Critic) implementation with Tensorflow \n",
        "with N step targets (missing terms are treated as 0). This is a multi-threaded \n",
        "discrete version. The code is tested with Gymâ€™s discrete action space \n",
        "environment, CartPole-v0 on Colab.\n",
        "\"\"\"\n",
        "\n",
        "import threading\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQso0DMQvaZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ACNet(object):\n",
        "    def __init__(self, scope, globalAC=None):   \n",
        "        if scope == net_scope: # global\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                # create global net\n",
        "                self.actor_params, self.critic_params = self._create_net(scope)[-2:] # only require params\n",
        "                \n",
        "        else: # local\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                self.a = tf.placeholder(tf.int32, [None, ], 'A')\n",
        "                self.critic_target = tf.placeholder(tf.float32, [None, 1], 'critic_target')\n",
        "                self.baselined_returns = tf.placeholder(tf.float32, [None, 1], 'baselined_returns') # for calculating advantage \n",
        "                # create local net\n",
        "                self.action_prob, self.V, self.actor_params, self.critic_params = self._create_net(scope)\n",
        "                    \n",
        "                TD_err = tf.subtract(self.critic_target, self.V, name='TD_err')\n",
        "                with tf.name_scope('actor_loss'):\n",
        "                    log_prob = tf.reduce_sum(tf.log(self.action_prob + 1e-5) * tf.one_hot(self.a, num_actions, dtype=tf.float32), axis=1, keep_dims=True)\n",
        "                    actor_component = log_prob * tf.stop_gradient(self.baselined_returns)\n",
        "                    # entropy for exploration\n",
        "                    entropy = -tf.reduce_sum(self.action_prob * tf.log(self.action_prob + 1e-5), axis=1, keep_dims=True)  # encourage exploration\n",
        "                    self.actor_loss = tf.reduce_mean( -(ENTROPY_BETA * entropy + actor_component) )                                        \n",
        "                with tf.name_scope('critic_loss'):\n",
        "                    self.critic_loss = tf.reduce_mean(tf.square(TD_err))                      \n",
        "                # accumulated gradients for local actor    \n",
        "                with tf.name_scope('local_actor_grad'):                   \n",
        "                    self.actor_zero_op, self.actor_accumu_op, self.actor_apply_op, actor_accum = self.accumu_grad(OPT_A, self.actor_loss, scope=scope + '/actor')\n",
        "                # accumulated gradients for local critic    \n",
        "                with tf.name_scope('local_critic_grad'):\n",
        "                    self.critic_zero_op, self.critic_accumu_op, self.critic_apply_op, critic_accum = self.accumu_grad(OPT_C, self.critic_loss, scope=scope + '/critic')\n",
        "                    \n",
        "            with tf.name_scope('params'): # push/pull from local/worker perspective\n",
        "                with tf.name_scope('push_to_global'):\n",
        "                    self.push_actor_params = OPT_A.apply_gradients(zip(actor_accum, globalAC.actor_params))\n",
        "                    self.push_critic_params = OPT_C.apply_gradients(zip(critic_accum, globalAC.critic_params))\n",
        "                with tf.name_scope('pull_fr_global'):\n",
        "                    self.pull_actor_params = [local_params.assign(global_params) for local_params, global_params in zip(self.actor_params, globalAC.actor_params)]\n",
        "                    self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, globalAC.critic_params)]                    \n",
        "                    \n",
        "    def _create_net(self, scope):\n",
        "        w_init = tf.glorot_uniform_initializer()\n",
        "        with tf.variable_scope('actor'):\n",
        "            hidden = tf.layers.dense(self.s, actor_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            action_prob = tf.layers.dense(hidden, num_actions, tf.nn.softmax, kernel_initializer=w_init, name='action_prob')        \n",
        "        with tf.variable_scope('critic'):\n",
        "            hidden = tf.layers.dense(self.s, critic_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            V = tf.layers.dense(hidden, 1, kernel_initializer=w_init, name='V')         \n",
        "        actor_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n",
        "        critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')       \n",
        "        return action_prob, V, actor_params, critic_params\n",
        "\n",
        "    def accumu_grad(self, OPT, loss, scope):\n",
        "        # retrieve trainable variables in scope of graph\n",
        "        #tvs = tf.trainable_variables(scope=scope + '/actor')\n",
        "        tvs = tf.trainable_variables(scope=scope)\n",
        "        # ceate a list of variables with the same shape as the trainable\n",
        "        accumu = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
        "        zero_op = [tv.assign(tf.zeros_like(tv)) for tv in accumu] # initialized with 0s\n",
        "        gvs = OPT.compute_gradients(loss, tvs) # obtain list of gradients & variables\n",
        "        #gvs = [(tf.where( tf.is_nan(grad), tf.zeros_like(grad), grad ), var) for grad, var in gvs]\n",
        "        # adds to each element from the list you initialized earlier with zeros its gradient \n",
        "        # accumu and gvs are in same shape, index 0 is grads, index 1 is vars\n",
        "        accumu_op = [accumu[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
        "        apply_op = OPT.apply_gradients([(accumu[i], gv[1]) for i, gv in enumerate(gvs)]) # apply grads\n",
        "        return zero_op, accumu_op, apply_op, accumu      \n",
        "      \n",
        "    def push_global_actor(self, feed_dict):  \n",
        "        SESS.run([self.push_actor_params], feed_dict)  \n",
        "\n",
        "    def push_global_critic(self, feed_dict):  \n",
        "        SESS.run([self.push_critic_params], feed_dict)         \n",
        "        \n",
        "    def pull_global(self):  \n",
        "        SESS.run([self.pull_actor_params, self.pull_critic_params])\n",
        "\n",
        "    def choose_action(self, s):  \n",
        "        prob_weights = SESS.run(self.action_prob, feed_dict={self.s: s[None, :]})\n",
        "        action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) \n",
        "        return action             \n",
        "        \n",
        "    def init_grad_storage_actor(self):\n",
        "        SESS.run(self.actor_zero_op)\n",
        "        \n",
        "    def accumu_grad_actor(self, feed_dict):\n",
        "        SESS.run([self.actor_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_actor(self, feed_dict):\n",
        "        SESS.run([self.actor_apply_op], feed_dict)   \n",
        "        \n",
        "    def init_grad_storage_critic(self):\n",
        "        SESS.run(self.critic_zero_op)\n",
        "        \n",
        "    def accumu_grad_critic(self, feed_dict):\n",
        "        SESS.run([self.critic_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_critic(self, feed_dict):\n",
        "        SESS.run([self.critic_apply_op], feed_dict)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8n6s3a5qIvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(object): # local only\n",
        "    def __init__(self, name, globalAC):\n",
        "        self.env = gym.make(game)\n",
        "        self.name = name\n",
        "        self.AC = ACNet(name, globalAC)\n",
        "    def work(self):\n",
        "        global GLOBAL_RUNNING_R, GLOBAL_EP\n",
        "        T = 0\n",
        "        t = 0\n",
        "        while not COORD.should_stop() and GLOBAL_EP < max_global_episodes:\n",
        "            s = self.env.reset()\n",
        "            ep_r = 0 # reward per episode\n",
        "            done = False\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "            while not done:\n",
        "                a = self.AC.choose_action(s)\n",
        "                s_, r, done, info = self.env.step(a)\n",
        "                ep_r += r\n",
        "                buffer_s.append(s)\n",
        "                buffer_a.append(a)\n",
        "                buffer_r.append(r)\n",
        "                buffer_done.append(done)                \n",
        "                s = s_\n",
        "                t += 1\n",
        "            \n",
        "            # if statement will always be done in this case... \n",
        "            # possible future modification\n",
        "            if done:\n",
        "                V_s = 0   \n",
        "            else:\n",
        "                V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n",
        "            \n",
        "            # critic related\n",
        "            critic_target = self.discount_rewards(buffer_r, GAMMA, V_s)\n",
        "            \n",
        "            buffer_s, buffer_a, critic_target = np.vstack(buffer_s), np.array(buffer_a), np.vstack(critic_target)\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.critic_target: critic_target}                         \n",
        "            self.AC.accumu_grad_critic(feed_dict) # accumulating gradients for local critic  \n",
        "            self.AC.apply_accumu_grad_critic(feed_dict) \n",
        "            \n",
        "            baseline = SESS.run(self.AC.V, {self.AC.s: buffer_s}) # Value function\n",
        "            epr = np.vstack(buffer_r).astype(np.float32)\n",
        "            n_step_targets = self.compute_n_step_targets_missing(epr, baseline, GAMMA, N_step) # Q values\n",
        "            # Advantage function\n",
        "            baselined_returns = n_step_targets - baseline\n",
        "\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.a: buffer_a, self.AC.critic_target: critic_target, self.AC.baselined_returns: baselined_returns}            \n",
        "            self.AC.accumu_grad_actor(feed_dict) # accumulating gradients for local actor  \n",
        "            \n",
        "            # update\n",
        "            self.AC.push_global_actor(feed_dict)                \n",
        "            self.AC.push_global_critic(feed_dict)\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "              \n",
        "            #if T % delay_rate == 0: # delay clearing of local gradients storage to reduce noise\n",
        "                # apply to local\n",
        "                #self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n",
        "                #self.AC.init_grad_storage_critic() \n",
        "\n",
        "            self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n",
        "            self.AC.init_grad_storage_critic() \n",
        "                \n",
        "            GLOBAL_RUNNING_R.append(ep_r) # for display\n",
        "            GLOBAL_EP += 1                           \n",
        "      \n",
        "    def discount_rewards(self, r, gamma, running_add):\n",
        "      \"\"\"Take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "      discounted_r = np.zeros_like(r)\n",
        "      #running_add = 0\n",
        "      for t in reversed(range(len(r))):\n",
        "          running_add = running_add * gamma + r[t]\n",
        "          discounted_r[t] = running_add\n",
        "      return discounted_r \n",
        "  \n",
        "    # As n increase, variance increase.\n",
        "    # Create a function that returns an array of n-step targets, one for each timestep:\n",
        "    # target[t] = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^n V(s_{t+n})\n",
        "    # Where r_t is given by episode reward (epr) and V(s_n) is given by the baselines.\n",
        "    def compute_n_step_targets_missing(self, epr, baselines, gamma, N):\n",
        "      targets = np.zeros_like(epr)    \n",
        "      if N > epr.size:\n",
        "        N = epr.size\n",
        "      for t in range(epr.size):    \n",
        "        for n in range(N):\n",
        "          if t+n == epr.size:            \n",
        "            break # missing terms treated as 0\n",
        "          if n == N-1: # last term\n",
        "            targets[t] += (gamma**n) * baselines[t+n]\n",
        "          else:\n",
        "            targets[t] += (gamma**n) * epr[t+n] \n",
        "      return targets   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Y3NFAbZq1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game = 'CartPole-v0'\n",
        "#env = gym.make(game).unwrapped\n",
        "env = gym.make(game)\n",
        "\n",
        "num_obvs = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "net_scope = 'global'\n",
        "max_global_episodes = 500\n",
        "delay_rate = 4000 # T steps\n",
        "\n",
        "#num_workers = multiprocessing.cpu_count()\n",
        "num_workers = 4 #16\n",
        "\n",
        "GAMMA = 0.999 #0.99\n",
        "ENTROPY_BETA = 0.1 #0.01\n",
        "actor_alpha = 0.01   \n",
        "critic_alpha = 0.01   \n",
        "actor_hidden = 128 #200\n",
        "critic_hidden = 128 #200\n",
        "N_step = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrwcW1f01-z",
        "colab_type": "code",
        "outputId": "b6843ac6-efb4-401f-ae8d-3de2f8d983d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "SESS = tf.Session()   \n",
        "with tf.device(\"/cpu:0\"):\n",
        "    OPT_A = tf.train.AdamOptimizer(actor_alpha, beta1=0.99, beta2=0.999, name='OPT_A')\n",
        "    OPT_C = tf.train.AdamOptimizer(critic_alpha, beta1=0.99, beta2=0.999, name='OPT_C')\n",
        "\n",
        "    GLOBAL_AC = ACNet(net_scope, globalAC=None) # only need its params\n",
        "    workers = []\n",
        "    for i in range(num_workers): # Create worker\n",
        "        i_name = 'W_%i' % i # worker name\n",
        "        workers.append(Worker(i_name, GLOBAL_AC))   \n",
        "        \n",
        "    GLOBAL_RUNNING_R = []\n",
        "    GLOBAL_EP = 0\n",
        "        \n",
        "    COORD = tf.train.Coordinator()\n",
        "    SESS.run(tf.global_variables_initializer())\n",
        "            \n",
        "    worker_threads = []\n",
        "    for worker in workers:\n",
        "        job = lambda: worker.work()\n",
        "        t = threading.Thread(target=job)\n",
        "        t.start()\n",
        "        worker_threads.append(t)\n",
        "    COORD.join(worker_threads)\n",
        "    \n",
        "    # display\n",
        "    plt.plot(np.arange(len(GLOBAL_RUNNING_R)), GLOBAL_RUNNING_R)\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.show()   \n",
        "    \n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 13:33:29.885300 140712893831040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0617 13:33:29.887572 140712893831040 deprecation.py:323] From <ipython-input-2-cf49427a73a9>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0617 13:33:30.344607 140712893831040 deprecation.py:506] From <ipython-input-2-cf49427a73a9>:20: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0617 13:33:30.361192 140712893831040 deprecation.py:323] From <ipython-input-2-cf49427a73a9>:59: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUTxRgVAURVE8+f/qKKvhvC7+9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--- 49.19171071052551 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}