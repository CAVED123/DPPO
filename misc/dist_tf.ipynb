{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dist_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lih6RiMej7_C",
        "colab_type": "code",
        "outputId": "901cb560-b21c-44c9-ff5a-da94923b0307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "\"\"\"\n",
        "Distributed Tensorflow with Python multiprocessing package. This program\n",
        "demonstrates how to use distributed Tensorflow with Pythonâ€™s multiprocessing \n",
        "package. A tf.FIFOQueue is used as a storage across processes.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from multiprocessing import Process\n",
        "from time import sleep\n",
        "\n",
        "cluster = tf.train.ClusterSpec({\n",
        "    \"worker\": [\"localhost:2223\",\n",
        "               \"localhost:2224\"\n",
        "              ],\n",
        "    \"ps\": [\"localhost:2225\"]\n",
        "})\n",
        "\n",
        "def parameter_server():\n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        var = tf.Variable(0.0, name='var')        \n",
        "        q = tf.FIFOQueue(10, tf.float32, shared_name=\"shared_queue\") \n",
        "        \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"ps\",\n",
        "                             task_index=0)\n",
        "    sess = tf.Session(target=server.target)\n",
        "    \n",
        "    print(\"Parameter server: waiting for cluster connection...\")\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Parameter server: cluster ready!\")\n",
        "    \n",
        "    print(\"Parameter server: initializing variables...\")\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Parameter server: variables initialized\")\n",
        "    \n",
        "    for i in range(10):\n",
        "        print(\"Parameter server: var has value %.1f\" % sess.run(var))\n",
        "        #print(\"ps: r\", sess.run(qd))\n",
        "        sleep(1.0)\n",
        "        if sess.run(var) == 10.0:\n",
        "          break\n",
        "    \n",
        "    sleep(3.0)\n",
        "    #print(\"ps: final r\", sess.run(qd))\n",
        "    print(\"ps q.size(): \", sess.run(q.size()))  \n",
        "    \n",
        "    for j in range(sess.run(q.size())):\n",
        "        print(\"ps: r\", sess.run(q.dequeue()))\n",
        "\n",
        "    #print(\"Parameter server: blocking...\")\n",
        "    #server.join() # currently blocks forever    \n",
        "    print(\"Parameter server: ended...\")\n",
        "\n",
        "def worker(worker_n): \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        q = tf.FIFOQueue(10, tf.float32, shared_name=\"shared_queue\")     \n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "                        worker_device='/job:worker/task:' + str(worker_n),\n",
        "                        cluster=cluster)):\n",
        "        var = tf.Variable(0.0, name='var')\n",
        "        \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"worker\",\n",
        "                             task_index=worker_n)\n",
        "    sess = tf.Session(target=server.target)\n",
        "    \n",
        "    print(\"Worker %d: waiting for cluster connection...\" % worker_n)\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Worker %d: cluster ready!\" % worker_n)\n",
        "    \n",
        "    while sess.run(tf.report_uninitialized_variables()):\n",
        "        print(\"Worker %d: waiting for variable initialization...\" % worker_n)\n",
        "        sleep(1.0)\n",
        "    print(\"Worker %d: variables initialized\" % worker_n)\n",
        "    \n",
        "    for i in range(5):\n",
        "        print(\"Worker %d: incrementing var\" % worker_n, sess.run(var))\n",
        "        sess.run(var.assign_add(1.0))\n",
        "        qe = q.enqueue(sess.run(var))\n",
        "        sess.run(qe)\n",
        "        #qd = q.dequeue()\n",
        "        #print(\"Worker %d: r\" % worker_n, sess.run(qd))\n",
        "        sleep(1.0)\n",
        "      \n",
        "    #print(\"Worker %d q.size(): \" % worker_n, sess.run(q.size()))  \n",
        "    \n",
        "    #print(\"Worker %d: blocking...\" % worker_n)\n",
        "    #server.join() # currently blocks forever\n",
        "    print(\"Worker %d: ended...\" % worker_n)\n",
        "    \n",
        "ps_proc = Process(target=parameter_server, daemon=True)\n",
        "w1_proc = Process(target=worker, args=(0, ), daemon=True)\n",
        "w2_proc = Process(target=worker, args=(1, ), daemon=True)\n",
        "\n",
        "ps_proc.start()\n",
        "w1_proc.start()\n",
        "w2_proc.start()\n",
        "\n",
        "ps_proc.join() # wait for all child processes to finish\n",
        "#w1_proc.join()\n",
        "#w2_proc.join()\n",
        "\n",
        "for proc in [w1_proc, w2_proc, ps_proc]:\n",
        "    proc.terminate() # only way to kill server is to kill it's process\n",
        "        \n",
        "print('All done.')            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Parameter server: waiting for cluster connection...\n",
            "Worker 0: waiting for cluster connection...\n",
            "Worker 1: waiting for cluster connection...\n",
            "Worker 1: cluster ready!\n",
            "Worker 1: waiting for variable initialization...\n",
            "Parameter server: cluster ready!\n",
            "Parameter server: initializing variables...\n",
            "Parameter server: variables initialized\n",
            "Parameter server: var has value 0.0\n",
            "Worker 0: cluster ready!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 0: variables initialized\n",
            "Worker 0: incrementing var 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 1: variables initialized\n",
            "Worker 1: incrementing var 1.0\n",
            "Parameter server: var has value 2.0\n",
            "Worker 0: incrementing var 2.0\n",
            "Worker 1: incrementing var 3.0\n",
            "Parameter server: var has value 4.0\n",
            "Worker 0: incrementing var 4.0\n",
            "Worker 1: incrementing var 5.0\n",
            "Parameter server: var has value 6.0\n",
            "Worker 0: incrementing var 6.0\n",
            "Worker 1: incrementing var 7.0\n",
            "Parameter server: var has value 8.0\n",
            "Worker 0: incrementing var 8.0\n",
            "Worker 1: incrementing var 9.0\n",
            "Worker 0: ended...\n",
            "Worker 1: ended...\n",
            "ps q.size():  10\n",
            "ps: r 1.0\n",
            "ps: r 2.0\n",
            "ps: r 3.0\n",
            "ps: r 4.0\n",
            "ps: r 5.0\n",
            "ps: r 6.0\n",
            "ps: r 7.0\n",
            "ps: r 8.0\n",
            "ps: r 9.0\n",
            "ps: r 10.0\n",
            "Parameter server: ended...\n",
            "All done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}