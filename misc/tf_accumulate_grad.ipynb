{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_accumulate_grad.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQso0DMQvaZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Accumulate gradients with Tensorflow.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def accumu_grad(self, OPT, loss, scope):\n",
        "    # retrieve trainable variables in scope of graph\n",
        "    #tvs = tf.trainable_variables(scope=scope + '/actor')\n",
        "    tvs = tf.trainable_variables(scope=scope)\n",
        "    \n",
        "    # ceate a list of variables with the same shape as the trainable\n",
        "    accumu = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
        "    \n",
        "    zero_op = [tv.assign(tf.zeros_like(tv)) for tv in accumu] # initialized with 0s\n",
        "    \n",
        "    gvs = OPT.compute_gradients(loss, tvs) # obtain list of gradients & variables\n",
        "    #gvs = [(tf.where( tf.is_nan(grad), tf.zeros_like(grad), grad ), var) for grad, var in gvs]\n",
        "    \n",
        "    # adds to each element from the list you initialized earlier with zeros its gradient \n",
        "    # accumu and gvs are in same shape, index 0 is grads, index 1 is vars\n",
        "    accumu_op = [accumu[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
        "    \n",
        "    apply_op = OPT.apply_gradients([(accumu[i], gv[1]) for i, gv in enumerate(gvs)]) # apply grads\n",
        "    \n",
        "    return zero_op, accumu_op, apply_op, accumu                "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}